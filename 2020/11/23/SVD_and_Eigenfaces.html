<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Svd_and_eigenfaces | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Svd_and_eigenfaces" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="SVD and Eigenfaces" />
<meta property="og:description" content="SVD and Eigenfaces" />
<link rel="canonical" href="https://yuewangpl.github.io/SVD-and-Eigenfaces/2020/11/23/SVD_and_Eigenfaces.html" />
<meta property="og:url" content="https://yuewangpl.github.io/SVD-and-Eigenfaces/2020/11/23/SVD_and_Eigenfaces.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-23T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"SVD and Eigenfaces","url":"https://yuewangpl.github.io/SVD-and-Eigenfaces/2020/11/23/SVD_and_Eigenfaces.html","@type":"BlogPosting","headline":"Svd_and_eigenfaces","dateModified":"2020-11-23T00:00:00-06:00","datePublished":"2020-11-23T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://yuewangpl.github.io/SVD-and-Eigenfaces/2020/11/23/SVD_and_Eigenfaces.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/SVD-and-Eigenfaces/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://yuewangpl.github.io/SVD-and-Eigenfaces/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/SVD-and-Eigenfaces/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/SVD-and-Eigenfaces/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/SVD-and-Eigenfaces/about/">About Me</a><a class="page-link" href="/SVD-and-Eigenfaces/search/">Search</a><a class="page-link" href="/SVD-and-Eigenfaces/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Svd_and_eigenfaces</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-11-23T00:00:00-06:00" itemprop="datePublished">
        Nov 23, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="svd-and-eigenfaces">SVD and Eigenfaces</h1>

<p>Eigenface is a term first introduced by Sirovich and Kirby in 1987, which is a set of feature basis obtained by principle component analysis (PCA) building on singular value decomposition (SVD), to project the higher-dimensional face-image space to a lower dimension. So that a set of <strong>r</strong> basic features, which are called eigenpictures, and in this case, eigenfaces, can be used to perform linear combinations to achieve the total number of <strong>n</strong> face images, where <strong>r &lt; n</strong>.</p>

<p>Eigenface is the fundamental concept used for facial recognition. Later on, various preprocessing algorithms, such as gamma correction for illumination preprocessing, were built upon it to improve accuracy.</p>

<h2 id="svd">SVD</h2>

<p>Singular value decomposition is to find 3 factors U, Σ, and (V^{T})of a real matrix M, where U and (V^{T})are orthogonal matrices, and Σ is a diagonal matrix and the entries on the diagonal are called singular values.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image1.png" alt="" /></p>

<p>Figure 1: SVD by <a href="https://commons.wikimedia.org/wiki/User:Georg-Johann">Georg-Johann</a></p>

<p>The singular values in the Σ matrix are in descending order, i.e., if a matrix Σ has diagonal entries (\sigma_{1}), (\sigma_{2}), (\sigma_{3})…(\sigma_{n}) from left to right,</p>

<p>then,</p>

<p>(\sigma_{1})≥ (\sigma_{2})≥ (\sigma_{3})≥ … ≥ (\sigma_{n}).</p>

<p>For an m×n matrix <strong>M</strong>, with n linearly independent columns (i.e., rank n), the dimensions of its full singular value decomposition matrices are:</p>

<p>U Σ (V^{T})</p>

<p>m×m m×n n×n</p>

<p>However, even if <strong>m &gt; n</strong>, there will only be <strong>n</strong> non-trivial entries of σs in Σ, so the SVD matrices of <strong>M</strong> will be equivalent to consider only the first <strong>n</strong> rows of <strong>Σ</strong> and <strong>n</strong> columns of <strong>U</strong> since other entries of the product matrix of these 3 matrices will be 0s. Such SVD is called economy-sized decomposition.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image2.png" alt="" /></p>

<p>Figure 2: Economy-sized SVD</p>

<p>In the real-life scenario, an image of a person’s face can have millions of pixels with the development of photographic equipment. However, in that two-million-dimension vector space, there are directions containing much less information than others, so we would not want to analyze or compute or train algorithms with every bit of info in the two-million-dimension vector space; otherwise, it will increase the cost of time and space due to the amount of computation.</p>

<p>Singular value decomposition can be used to compress images by truncating SVD matrices to lower dimensions. Since the components with the most important information are ordered to be in the front, we can use the first <strong>r</strong> rows and columns to compress an image to reduce not-as-important information in the picture, by truncating the SVD matrices to rank <strong>r</strong>.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image3.png" alt="" /></p>

<p>Figure 3: Approximated matrix M-hat by truncating SVD</p>

<p>I will use a picture of my cat with a resolution of this picture is 1920×1080 as an example of such approximation.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image4.jpg" alt="" /></p>

<p>Figure 4: Original cat image</p>

<p>The components in this image include the cat (“mooncake”), its leash, a part of a trunk, and snow. Now we can use SVD to compress this picture to see if those pieces of information are reserved. SVD can be computed with linear algebra (linalg) package under numpy in python. We can first plot the singular values to see how much information each value has. And as shown in figure 5 and 6, it is obvious that the first couple of dozens of columns in SVD matrices will give us the majority of information from the original picture.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image5.png" alt="" /></p>

<p>Figure 5: Plotted singular values</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image6.png" alt="" /></p>

<p>Figure 6: Cumulative proportions of singular values</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image7.png" alt="" /></p>

<p>Figure 7: Compressed cat image to rank <strong>r</strong></p>

<p>As shown in figure 6, when we truncate the SVD matrices by keeping <strong>r</strong> singular values, when <strong>r</strong> = 5, an image of color blocks is reproduced, where we can identify an animal, may be a rabbit, and an object on the right.</p>

<p>Moving on, the information we identified from the original picture is already able to be found with first 20 components. And by keeping 100 singular values, the compressed image is quite clear.</p>

<h2 id="using-yale-face-database-b">Using Yale Face Database B</h2>

<p>There are 38 human objects in total from <a href="http://vision.ucsd.edu/~leekc/ExtYaleDatabase/Yale%20Face%20Database.htm"><span class="underline">Yale Face Database B</span></a> and <a href="http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html"><span class="underline">Extended Yale Face Database B</span></a>. The first 36 objects can be used as a training set and the last two faces can be used as a test set.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image8.png" alt="" /></p>

<p>Figure 8: The first 36 gray-scaled objects from Yale Face Database B</p>

<p>Every face image has 168×192 pixels and images are aligned so that eyebrows, eyes, noses, and mouths are at a similar position in the pictures of the dataset. Face images are then being stretched to column vectors and all face-vectors are horizontally concatenated to construct a face matrix X.</p>

<p>To perform PCA, an average face needs to be calculated by finding the mean of all dimensions. The average face can be reshaped as an image after computing.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image9.png" alt="" /></p>

<p>Figure 9: The average face</p>

<p>Then subtract the mean from face matrix <strong>X</strong> to recenter data around the origin. We can name the resulting matrix A.</p>

<p>After finding singular value decomposition of matrix A, column vectors in U are eigenvectors of the covariance matrix of A, which is also called eigenfaces.</p>

<p>The first 8 eigenfaces can be found by reshaping the first 8 columns of U (U[:, 0:7]) to size 168×192 matrices:</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image10.png" alt="" /></p>

<p>Figure 10: The first 8 eigenfaces</p>

<p>As shown in figure 10, the first principal component gives a general shape of a human face. As defined in PCA, the principal components are ordered descendingly by how much variances each principal component captures, which is the reason that eigenface 1 looks like all human faces with only the elliptical shapes of face and eyes and showing the existence of nose and mouth. The columns after that capture more features such as lips, eyebrows, shadows, and muscles on the face.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image11.png" alt="" /></p>

<p>Figure 11: The 51th eigenface</p>

<p>We can project new faces that were not used in the training dataset to the first <strong>r</strong> eigenfaces to store data with a lower volume of memory by ({U_{r}^{T}}^{})× x, and use <strong>r</strong> eigenfaces as the basis for linear combinations to achieve an approximation of these new faces.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image12.png" alt="" /></p>

<p>Figure 12: The 37th object original image (top left) and linear composition of first <strong>r</strong> eigenfaces</p>

<p>As we can see, when r=800, the approximated picture is already good enough to reproduce the face of subject 37, so that the computation cost is reduced by a large amount comparing to the 32,256-dimension vector space of the original images.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image13.png" alt="" /></p>

<p>Figure 13: The 38th object original image (top) and linear composition of first <strong>r</strong> eigenfaces.</p>

<p>To differentiate people, for example, person 37 and 38 who were not in the training set, we can project them onto a plane given by two principal components because there are only two people to choose from.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image14.png" alt="" /></p>

<p>Figure 14: Singular values of original face matrix</p>

<p>After plotting singular values, figure 14 tells us by the color, that the first four singular values are much larger than the rest of them, thus, the first four columns of matrix U would capture a lot more variations than the rest of the columns, resulting in the worse split between points of different classes (faces).</p>

<p>Hence, we can project the mean-subtracted 37th and 38th faces after stretching them to column vectors, to the plane constructed by the eigenfaces 5 and 6, i.e., column numbers 4 and 5 in U since numbers start from 0 in python.</p>

<p>The coordinates of points is calculated by:</p>

<p>(U^{T})[:, [4,5]] × Face_37</p>

<p>Here is the resulting plot.</p>

<p><img src="https://YueWangpl.github.io/SVD-and-Eigenfaces/assets/img/2020-11-23-SVD_and_Eigenfaces/media/image15.png" alt="" /></p>

<p>Figure 15: Projection of object 37 and 38 onto PC5-PC6 plane</p>

<p>After projection, Figure 15 tells us that most of the data of object 37 lie in the positive region of PC6, and object 38 has data that are more negative in PC6, while having a larger standard deviation in principal component 6. From here, we can train algorithms to recognize these faces with more principal components included.</p>

<h3 id="references">References:</h3>

<p>Hu, C., Lu, X., Ye, M., &amp; Zeng, W. (2017). Singular value decomposition and local near neighbors for face recognition under varying illumination. Pattern Recognition, 64, 60–83. https://doi.org/10.1016/j.patcog.2016.10.029</p>

<p>Steve Brunton. (2020, January 19). Singular Value Decomposition [Video]. YouTube. <a href="https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv"><span class="underline">https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv</span></a></p>

<p>Georghiades, A.S. and Belhumeur, P.N. and Kriegman, D.J. From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose. IEEE Trans. Pattern Anal. Mach. Intelligence 23(6):643-660 (2001).</p>

  </div><a class="u-url" href="/SVD-and-Eigenfaces/2020/11/23/SVD_and_Eigenfaces.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/SVD-and-Eigenfaces/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/SVD-and-Eigenfaces/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/SVD-and-Eigenfaces/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/SVD-and-Eigenfaces/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/SVD-and-Eigenfaces/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
